{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "30526d08-5129-4e81-b5da-f880d11616eb",
   "metadata": {},
   "source": [
    "# FPN-AbMIL --> best model "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48a56722-8a0a-4122-a40b-1062e763c0a1",
   "metadata": {},
   "source": [
    "## Image Classification "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f9312ad-f3ce-4c72-a599-a38997c3ad47",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%run main.py \\\n",
    "--clip_chk_pt_path \"foundational_models/Mammo-CLIP-main/b2-model-best-epoch-10.tar\" \\\n",
    "--dataset 'ViNDr' \\\n",
    "--label \"Mass\" \\\n",
    "--train --epochs 30 --batch-size 8 \\\n",
    "--eval_scheme 'kruns_train+val+test' --n_runs 1 \\\n",
    "--lr 5.0e-5 \\\n",
    "--weighted-BCE 'y' \\\n",
    "--mil_type 'pyramidal_mil' \\\n",
    "--multi_scale_model 'fpn' \\\n",
    "--fpn_dim 256 \\\n",
    "--fcl_encoder_dim 256 \\\n",
    "--fcl_dropout 0.25 \\\n",
    "--pooling_type 'gated-attention' \\\n",
    "--drop_attention_pool 0.25 \\\n",
    "--type_scale_aggregator 'gated-attention' \\\n",
    "--deep_supervision \\\n",
    "--scales 16 32 128 \n",
    "\n",
    "print('---------------finished running code-------------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0186f67b-2a36-4bfb-bdcf-a2adcbc33ab0",
   "metadata": {},
   "source": [
    "## Lesion Detection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7eb275b-e8ba-45c0-a5d9-93e1d0937d2d",
   "metadata": {},
   "source": [
    "### all lesions (mAP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b06a39f-dadf-407a-bb99-460db55d8d96",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "path = 'output/MIL_experiments/Mass/offline_feature_extraction/multi_scale/fpn-deep_supervision/scale_aggregator_gated-attention/encoder_mlp-dim_256-dropout_0.25/pooling_gated-attention-dropout_0.25-softmax/2025-06-26'\n",
    "\n",
    "%run main.py \\\n",
    "--clip_chk_pt_path \"foundational_models/Mammo-CLIP-main/b2-model-best-epoch-10.tar\" \\\n",
    "--dataset 'ViNDr' \\\n",
    "--label \"Mass\" \\\n",
    "--roi_eval \\\n",
    "--roi_eval_set 'test' \\\n",
    "--resume \"$path\" \\\n",
    "--feature_extraction 'online' \\\n",
    "--patch_size 512 \\\n",
    "--overlap 0.75 \\\n",
    "--mil_type 'pyramidal_mil' \\\n",
    "--fpn_dim 256 \\\n",
    "--multi_scale_model 'fpn' \\\n",
    "--fcl_encoder_dim 256 \\\n",
    "--fcl_dropout 0.25 \\\n",
    "--pooling_type 'gated-attention' \\\n",
    "--drop_attention_pool 0.25 \\\n",
    "--type_scale_aggregator 'gated-attention' \\\n",
    "--deep_supervision \\\n",
    "--scales 16 32 128 \n",
    "\n",
    "print('---------------finished running code-------------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d911cf78-bcfc-4c14-ba25-acbfb370b6f7",
   "metadata": {},
   "source": [
    "### small lesion (mAP_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1508469b-7ae7-4ec0-8393-8a26df028747",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "path = 'output/MIL_experiments/Mass/offline_feature_extraction/multi_scale/fpn-deep_supervision/scale_aggregator_gated-attention/encoder_mlp-dim_256-dropout_0.25/pooling_gated-attention-dropout_0.25-softmax/2025-06-26'\n",
    "\n",
    "%run main.py \\\n",
    "--clip_chk_pt_path \"foundational_models/Mammo-CLIP-main/b2-model-best-epoch-10.tar\" \\\n",
    "--dataset 'ViNDr' \\\n",
    "--label \"Mass\" \\\n",
    "--roi_eval \\\n",
    "--roi_eval_scheme 'small_roi'\n",
    "--roi_eval_set 'test' \\\n",
    "--resume \"$path\" \\\n",
    "--feature_extraction 'online' \\\n",
    "--patch_size 512 \\\n",
    "--overlap 0.75 \\\n",
    "--mil_type 'pyramidal_mil' \\\n",
    "--fpn_dim 256 \\\n",
    "--multi_scale_model 'fpn' \\\n",
    "--fcl_encoder_dim 256 \\\n",
    "--fcl_dropout 0.25 \\\n",
    "--pooling_type 'gated-attention' \\\n",
    "--drop_attention_pool 0.25 \\\n",
    "--type_scale_aggregator 'gated-attention' \\\n",
    "--deep_supervision \\\n",
    "--scales 16 32 128 \n",
    "\n",
    "print('---------------finished running code-------------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba55774a-ba8a-425f-8217-eb3eb7346a55",
   "metadata": {},
   "source": [
    "### medium lesions (mAP_m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a3888d5-6a49-4fca-a7d5-9639dd4a5ddc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "path = 'output/MIL_experiments/Mass/offline_feature_extraction/multi_scale/fpn-deep_supervision/scale_aggregator_gated-attention/encoder_mlp-dim_256-dropout_0.25/pooling_gated-attention-dropout_0.25-softmax/2025-06-26'\n",
    "\n",
    "%run main.py \\\n",
    "--clip_chk_pt_path \"foundational_models/Mammo-CLIP-main/b2-model-best-epoch-10.tar\" \\\n",
    "--dataset 'ViNDr' \\\n",
    "--label \"Mass\" \\\n",
    "--roi_eval \\\n",
    "--roi_eval_scheme 'medium_roi'\n",
    "--roi_eval_set 'test' \\\n",
    "--resume \"$path\" \\\n",
    "--feature_extraction 'online' \\\n",
    "--patch_size 512 \\\n",
    "--overlap 0.75 \\\n",
    "--mil_type 'pyramidal_mil' \\\n",
    "--fpn_dim 256 \\\n",
    "--multi_scale_model 'fpn' \\\n",
    "--fcl_encoder_dim 256 \\\n",
    "--fcl_dropout 0.25 \\\n",
    "--pooling_type 'gated-attention' \\\n",
    "--drop_attention_pool 0.25 \\\n",
    "--type_scale_aggregator 'gated-attention' \\\n",
    "--deep_supervision \\\n",
    "--scales 16 32 128  \n",
    "\n",
    "print('---------------finished running code-------------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2048f296-b917-417a-b72e-cfd1ac8de95d",
   "metadata": {},
   "source": [
    "### large lesions (mAP_l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "334f834f-00ac-4151-8870-a328bef50a4d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "path = 'output/MIL_experiments/Mass/offline_feature_extraction/multi_scale/fpn-deep_supervision/scale_aggregator_gated-attention/encoder_mlp-dim_256-dropout_0.25/pooling_gated-attention-dropout_0.25-softmax/2025-06-26'\n",
    "\n",
    "%run main.py \\\n",
    "--clip_chk_pt_path \"foundational_models/Mammo-CLIP-main/b2-model-best-epoch-10.tar\" \\\n",
    "--dataset 'ViNDr' \\\n",
    "--label \"Mass\" \\\n",
    "--roi_eval \\\n",
    "--roi_eval_scheme 'large_roi'\n",
    "--roi_eval_set 'test' \\\n",
    "--resume \"$path\" \\\n",
    "--feature_extraction 'online' \\\n",
    "--patch_size 512 \\\n",
    "--overlap 0.75 \\\n",
    "--mil_type 'pyramidal_mil' \\\n",
    "--fpn_dim 256 \\\n",
    "--multi_scale_model 'fpn' \\\n",
    "--fcl_encoder_dim 256 \\\n",
    "--fcl_dropout 0.25 \\\n",
    "--pooling_type 'gated-attention' \\\n",
    "--drop_attention_pool 0.25 \\\n",
    "--type_scale_aggregator 'gated-attention' \\\n",
    "--deep_supervision \\\n",
    "--scales 16 32 128  \n",
    "\n",
    "print('---------------finished running code-------------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2b583c4-852a-4495-8d18-ed44bc1690f8",
   "metadata": {},
   "source": [
    "# FPN-SetTrans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7bdd230-79f7-41e3-a2e2-8aebb8ed4f33",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%run main.py \\\n",
    "--clip_chk_pt_path \"foundational_models/Mammo-CLIP-main/b2-model-best-epoch-10.tar\" \\\n",
    "--dataset 'ViNDr' \\\n",
    "--label \"Mass\" \\\n",
    "--train --epochs 30 --batch-size 8 \\\n",
    "--eval_scheme 'kruns_train+val+test' --n_runs 1 \\\n",
    "--lr 5.0e-5 \\\n",
    "--weighted-BCE 'y' \\\n",
    "--mil_type 'pyramidal_mil' \\\n",
    "--multi_scale_model 'fpn' \\\n",
    "--fpn_dim 256 \\\n",
    "--fcl_encoder_dim 256 \\\n",
    "--fcl_dropout 0.25 \\\n",
    "--type_mil_encoder 'isab' \\\n",
    "--trans_layer_norm True \\\n",
    "--pooling_type 'pma' \\\n",
    "--drop_attention_pool 0.25 \\\n",
    "--type_scale_aggregator 'gated-attention' \\\n",
    "--deep_supervision \\\n",
    "--scales 16 32 128 \n",
    "\n",
    "print('---------------finished running code-------------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e83c3a39-f26d-4a5a-84a5-ddef5228fdb1",
   "metadata": {},
   "source": [
    "# Ablation Studies"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80132f7a-aba2-473c-b4d5-5f7912636332",
   "metadata": {},
   "source": [
    "## Effect of Different Multi-scale Instance Encoders "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f844cbda-79e8-4bce-aae5-c9136617ba34",
   "metadata": {},
   "source": [
    "### Based on Multi-scale Patches (MSP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b4114a7-25a9-48a4-a03f-4abb175c5bcd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%run main.py \\\n",
    "--clip_chk_pt_path \"foundational_models/Mammo-CLIP-main/b2-model-best-epoch-10.tar\" \\\n",
    "--dataset 'ViNDr' \\\n",
    "--label \"Mass\" \\\n",
    "--train --epochs 30 --batch-size 8 \\\n",
    "--eval_scheme 'kruns_train+val+test' --n_runs 1 \\\n",
    "--lr 5.0e-5 \\\n",
    "--weighted-BCE 'y' \\\n",
    "--mil_type 'pyramidal_mil' \\\n",
    "--multi_scale_model 'msp' \\\n",
    "--fcl_encoder_dim 256 \\\n",
    "--fcl_dropout 0.25 \\\n",
    "--pooling_type 'gated-attention' \\\n",
    "--drop_attention_pool 0.25 \\\n",
    "--type_scale_aggregator 'gated-attention' \\\n",
    "--deep_supervision \\\n",
    "--scales 128 256 384 \n",
    "\n",
    "print('---------------finished running code-------------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5837f42f-a998-4f55-93f8-d9658dc1ebcd",
   "metadata": {},
   "source": [
    "## Effect of Different Multi-scale Aggregators "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ac9cca6-9862-40ca-9117-ba83fff35077",
   "metadata": {},
   "source": [
    "### w/o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75181120-d71d-465e-a3cc-c261e1f2718d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%run main.py \\\n",
    "--clip_chk_pt_path \"foundational_models/Mammo-CLIP-main/b2-model-best-epoch-10.tar\" \\\n",
    "--dataset 'ViNDr' \\\n",
    "--label \"Mass\" \\\n",
    "--train --epochs 30 --batch-size 8 \\\n",
    "--eval_scheme 'kruns_train+val+test' --n_runs 1 \\\n",
    "--lr 5.0e-5 \\\n",
    "--weighted-BCE 'y' \\\n",
    "--mil_type 'pyramidal_mil' \\\n",
    "--multi_scale_model 'fpn' \\\n",
    "--fpn_dim 256 \\\n",
    "--fcl_encoder_dim 256 \\\n",
    "--fcl_dropout 0.25 \\\n",
    "--pooling_type 'gated-attention' \\\n",
    "--drop_attention_pool 0.25 \\\n",
    "--type_scale_aggregator 'mean_p' \\\n",
    "--deep_supervision \\\n",
    "--scales 16 32 128 \n",
    "\n",
    "print('---------------finished running code-------------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6724bbd8-23bb-4f5a-b3c4-d659f36274f6",
   "metadata": {},
   "source": [
    "### Concat "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29ed2e4f-d026-4f4f-9fbe-15d9b1597212",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%run main.py \\\n",
    "--clip_chk_pt_path \"foundational_models/Mammo-CLIP-main/b2-model-best-epoch-10.tar\" \\\n",
    "--dataset 'ViNDr' \\\n",
    "--label \"Mass\" \\\n",
    "--train --epochs 30 --batch-size 8 \\\n",
    "--eval_scheme 'kruns_train+val+test' --n_runs 1 \\\n",
    "--lr 5.0e-5 \\\n",
    "--weighted-BCE 'y' \\\n",
    "--mil_type 'pyramidal_mil' \\\n",
    "--multi_scale_model 'fpn' \\\n",
    "--fpn_dim 256 \\\n",
    "--fcl_encoder_dim 256 \\\n",
    "--fcl_dropout 0.25 \\\n",
    "--pooling_type 'gated-attention' \\\n",
    "--drop_attention_pool 0.25 \\\n",
    "--type_scale_aggregator 'concatenation' \\\n",
    "--deep_supervision \\\n",
    "--scales 16 32 128 \n",
    "\n",
    "print('---------------finished running code-------------------')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

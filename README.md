# Multi-scale Attention-based Multiple Instance Learning (MIL)

This repository contains the **official implementation** of the paper:
ğŸ“„ [**"Multi-scale Attention-based Multiple Instance Learning for Breast Cancer Diagnosis"**](https://link.springer.com/chapter/10.1007/978-3-032-05182-0_36)
Accepted at the **MICCAI 2025** conference for oral presentation and poster session. 

## Repository Structure

```plaintext
Multi-scale-Attention-based-MIL/
â”‚â”€â”€ Datasets/                  
â”‚   â”œâ”€â”€ dataset_concepts.py                 # Dataset classes for MIL classification & lesion detection   
â”‚   â””â”€â”€ dataset_utils.py                    # Data preprocessing & loading    
â”‚â”€â”€ Feature_Extractors/                   
â”‚   â”œâ”€â”€ __init__.py                         # Load feature extractor  
â”‚   â”œâ”€â”€ FPN.py                              # Feature Pyramid Network
â”‚   â””â”€â”€ mammoclip/                          
â”‚       â”œâ”€â”€ __init__.py                     # Load pre-trained MammoCLIP image encoder
â”‚       â”œâ”€â”€ efficient_net_custom_utils.py   # Helper functions for EfficientNet 
â”‚       â””â”€â”€ efficientnet_custom.py          # Modified EfficientNet implementation 
â”‚â”€â”€ MIL/                                    
â”‚   â”œâ”€â”€ __init__.py                         # Build & configure MIL model
â”‚   â”œâ”€â”€ MIL_models.py                       # MIL model architectures
â”‚   â”œâ”€â”€ AttentionModels.py                  # Attention-based MIL modules   
â”‚   â”œâ”€â”€ MIL_experiment.py                   # MIL classification training & evaluation 
â”‚   â”œâ”€â”€ inference_MIL_classifier.py         # MIL classification inference   
â”‚   â””â”€â”€ roi_eval.py                         # Lesion detection MIL evaluation 
â”‚â”€â”€ utils/                                  
â”‚   â”œâ”€â”€ data_split_utils.py                 # Data splitting utilities    
â”‚   â”œâ”€â”€ generic_utils.py                    # General-purpose utilities 
â”‚   â”œâ”€â”€ plot_utils.py                       # Plotting & visualization 
â”‚   â”œâ”€â”€ training_setup_utils.py             # Training setup & configuration
â”‚   â””â”€â”€ metrics.py                          # Evaluation metrics 
â”‚â”€â”€ vindrmammo_grouped_df.csv               # Dataset metadata (e.g. file names & labels)  
â”‚â”€â”€ main.py                                 # Main script to train & evaluate implemented models 
â”‚â”€â”€ offline_feature_extraction.py           # Script for offline feature extraction  
````

# Data Download

As mentioned in the paper, this work uses the preprocessed images provided by Ghosh et al. in their Mammo-CLIP work. 
- [Link to input images](https://www.kaggle.com/datasets/shantanughosh/vindr-mammogram-dataset-dicom-to-png)

Regarding metadata information for the downstream tasks (image classification and lesion detection), please use the **vindrmammo_grouped_df.csv** provided in this repository. 

# Checkpoints

We provide pre-training checkpoints for our best-performing models.  

|Description         | Checkpoints |
|--------------------|-------------|
| Best model for calcifications | [FPN-SetTrans](https://drive.google.com/file/d/1pcr5wa8cI7R8L-7MfkXBEBB2IE02NmMI/view?usp=sharing) |
| Best model for masses | [FPN-AbMIL](https://drive.google.com/file/d/1ptgub09TjB2oCpm2ij2OyaVDKT_5y8D0/view?usp=sharing) |

## â³ Coming Soon (under construction) 
- [ ] Scripts for training and evaluating **MIL classification tasks**
- [ ] Scripts for post-hoc evaluation of **lesion detection tasks**
- [ ] Jupyter Notebooks to reproduce **MICCAI 2025 results**
